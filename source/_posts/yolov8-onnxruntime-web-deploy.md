---
title: åŸºäºONNXçš„Webç«¯YOLOv8æ¨¡å‹éƒ¨ç½²ä¸æ¨ç†
date: 2024-04-10 16:14:31
categories: CV
tags:
  - ç›®æ ‡æ£€æµ‹
  - yolo
  - onnx
permalink: yolov8-onnxruntime-web-deploy
---
ä¹‹å‰çš„ä¸€äº›å®éªŒï¼Œä¸»è¦é›†ä¸­åœ¨æ¨¡å‹çš„æ­å»ºã€è®­ç»ƒå’Œè°ƒä¼˜ä¸Šï¼Œæ²¡æœ‰æ¶‰åŠéƒ¨ç½²çš„ç¯èŠ‚ï¼Œæ‰€ä»¥è¿™æ¬¡å°è¯•å°†æ¨¡å‹éƒ¨ç½²åˆ°ç«¯ä¾§è®¾å¤‡ï¼ˆæµè§ˆå™¨ï¼‰ï¼Œæ¥ç†Ÿæ‚‰ä¸€ä¸‹éƒ¨ç½²çš„æµç¨‹ã€‚
<!--more-->
**æ•´ä¸ªè¿‡ç¨‹å¤§è‡´åŒ…å«å¦‚ä¸‹æ­¥éª¤ï¼š**
- YOLOv8çš„è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒ
- YOLOv8æ¨¡å‹å¯¼å‡ºonnxæ ¼å¼
- æ­é…onnxruntimeçš„æ•°æ®é¢„å¤„ç†
- æ­é…onnxruntimeçš„æ•°æ®åå¤„ç†
- åŸºäºonnxruntimeçš„æ¨¡å‹é‡åŒ–
- é’ˆå¯¹CPU (wasm) execution providerçš„æ€§èƒ½ä¼˜åŒ–æªæ–½

**æœ€ç»ˆæ•ˆæœï¼š** è®©æ¨¡å‹åœ¨PCç«¯æµè§ˆå™¨ä¸­è¿è¡Œï¼Œé€šè¿‡è°ƒç”¨ç«¯ä¾§æ‘„åƒå¤´ï¼Œå®ç°äº†ç›®æ ‡æ£€æµ‹çš„åŠŸèƒ½ã€‚
![demo](../images/rps_demo.png)

**é¡¹ç›®å®Œæ•´ä»£ç å‚è€ƒï¼š**[è¿™ä¸ªä»“åº“](https://github.com/satorioh/yolov8_onnx_js)

**demoåœ°å€ï¼š**[Paper, Rock, Scissors Webcam Detection](https://rps.regulusai.top/)

```
å»ºè®®ï¼š
1.ä½¿ç”¨PCç«¯æµè§ˆå™¨å¼€å¯demoï¼Œæ‰‹æœºç«¯ç®—åŠ›èµ„æºæœ‰é™ï¼Œæ¨ç†é€Ÿåº¦è¾ƒæ…¢
2.éœ€è¦ç»™äºˆæµè§ˆå™¨æ‘„åƒå¤´æƒé™
3.ç”±äºéƒ¨ç½²åœ¨vercelæµ·å¤–èŠ‚ç‚¹ï¼Œå¯¹äºå¤§æ–‡ä»¶ï¼ˆæ¨¡å‹ï¼‰çš„ä¼ è¾“ï¼Œé€Ÿåº¦ä¸å¤ªç¨³å®šï¼Œå¦‚è¶…è¿‡2minä»åœ¨loadingï¼Œå¯ä»¥åˆ·æ–°å†è¯•
```

### ä¸€ã€å‰æœŸå‡†å¤‡
#### 1.æ•°æ®é›†
è€ƒè™‘åˆ°æœ€ç»ˆæ•ˆæœéœ€è¦ç›´è§‚ã€æ¸…æ™°ã€æ˜“ç†è§£ï¼Œè¿™æ¬¡é€‰æ‹©äº†roboflowä¸Šçš„[çŸ³å¤´å‰ªåˆ€å¸ƒ](https://universe.roboflow.com/roboflow-58fyf/rock-paper-scissors-sxsw)ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼š
![rps_dataset_preview](../images/rps_dataset_preview.gif)

roboflowå®˜æ–¹å·²ç»å¯¹è¯¥æ•°æ®é›†åšäº†å‡ ä¸ªç‰ˆæœ¬çš„è¿­ä»£ï¼Œå¹¶ä¸”æ·»åŠ äº†é¢„å¤„ç†å’Œæ•°æ®å¢å¼ºï¼ˆå¦‚ä¸‹å›¾ï¼‰
![rps_dataset_desc](../images/rps_dataset_desc.png)

æˆ‘ä¸‹è½½çš„æ˜¯[v14ç‰ˆæœ¬](https://universe.roboflow.com/roboflow-58fyf/rock-paper-scissors-sxsw/dataset/14)ï¼ŒåŒ…å«3ä¸ªç±»åˆ«ï¼ˆRockã€Paperã€Scissorsï¼‰ï¼Œ7335å¼ å›¾ç‰‡ï¼ˆè®­ç»ƒé›†6445ã€éªŒè¯é›†576ã€æµ‹è¯•é›†304ï¼‰ï¼Œå›¾ç‰‡å°ºå¯¸ç»Ÿä¸€reshapeæˆäº†640x640ï¼Œè™½ç„¶å›¾ç‰‡æ•°é‡å¾ˆå¤šï¼Œä½†æ¯å¼ åªæœ‰å‡ åkbï¼Œæ‰€ä»¥æ•´ä¸ªæ•°æ®é›†ä¹Ÿå°±238Mã€‚

#### 2.ç«¯ä¾§è®¾å¤‡ä¸é¢„è®­ç»ƒæ¨¡å‹é€‰æ‹©
ç«¯ä¾§è®¾å¤‡ï¼šè¿™æ¬¡é€‰æ‹©äº†æµè§ˆå™¨ç«¯æ¥éƒ¨ç½²ï¼Œä¸€æ˜¯å› ä¸ºè‡ªå·±å¯¹jsæ¯”è¾ƒç†Ÿæ‚‰ï¼ˆè€æœ¬è¡Œå˜›ï¼‰ï¼ŒäºŒæ˜¯æµè§ˆå™¨ç«¯æœ‰å…¶å¤©ç„¶ä¼˜åŠ¿ï¼š
- æ›´å¿«ï¼šç›´æ¥æŠŠæ¨¡å‹æ”¾åœ¨æµè§ˆå™¨é‡Œè¿è¡Œï¼Œçœå»äº†è¯·æ±‚åç«¯çš„æ—¶é—´
- æ›´å®‰å…¨ï¼šå› ä¸ºæ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œå³ä½¿ç¦»çº¿ä¹Ÿå¯è¿è¡Œï¼Œä¿è¯äº†ä¸€å®šçš„æ•°æ®éšç§
- æ›´ä¾¿å®œï¼šç›´æ¥ä½¿ç”¨å®¢æˆ·ç«¯èµ„æºåšæ¨ç†ï¼Œçœå»äº†ç§Ÿèµäº‘ç«¯ç®—åŠ›çš„å¼€é”€

é¢„è®­ç»ƒæ¨¡å‹é€‰æ‹©ï¼šè€ƒè™‘åˆ°æµè§ˆå™¨åŠ è½½æ¨¡å‹çš„è€—æ—¶ï¼Œä»¥åŠä»»åŠ¡æœ¬èº«çš„ç²¾åº¦è¦æ±‚ï¼Œé€‰æ‹©YOLOv8ä¸­æœ€å°çš„æ¨¡å‹YOLOv8næ¯”è¾ƒåˆé€‚

### äºŒã€æ¨¡å‹è®­ç»ƒ
è®­ç»ƒæ–¹æ³•å¯ä»¥å‚è€ƒæˆ‘ä¹‹å‰çš„[åŸºäºYOLOv8çš„èœå“æ£€æµ‹å®éªŒ](https://wandb.ai/wangbinxp/yolov8_food/reports/-YOLOv8---Vmlldzo3MzEwOTE4?accessToken=uq09cnk2aei7x4669t03bnwsgrk53v00gf0fvbm80w7jb52gt7isyym17xy4thu4)ï¼Œåªæ˜¯æ•°æ®é›†æ¢æˆäº†çŸ³å¤´å‰ªåˆ€å¸ƒï¼Œå»æ‰äº†è¶…å‚æ•°è°ƒä¼˜çš„ç¯èŠ‚ã€‚

ä½¿ç”¨yolov8næ¨¡å‹ï¼Œè·‘100è½®ï¼Œé€šè¿‡wandbè®°å½•è®­ç»ƒè¿‡ç¨‹ï¼Œæ ¸å¿ƒnotebookä»£ç å¦‚ä¸‹ï¼š
```python
model = YOLO('yolov8n.pt')
results = model.train(project="yolov8_rps", data='./datasets/data.yaml', epochs=100, imgsz=640)
```

æœ€ç»ˆè®­ç»ƒç»“æœå¦‚ä¸‹ï¼Œé™¤äº†mAP50-95ä½äº†ç‚¹ï¼Œå…¶ä»–éƒ½åœ¨90ä»¥ä¸Šï¼š
![rps_train_result](../images/rps_train_result.png)


ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè·‘ä¸€ä¸‹è§†é¢‘æ¨ç†ï¼ˆå¦‚ä¸‹ï¼‰ï¼Œæ•ˆæœè¿˜å¯ä»¥
<iframe src="//player.bilibili.com/player.html?aid=1502879386&bvid=BV1mD421H7Mc&cid=1500625973&p=1&autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

### ä¸‰ã€æ¨¡å‹å¯¼å‡ºonnxæ ¼å¼
#### 1.ä»€ä¹ˆæ˜¯ONNXå’ŒONNX Runtime
ONNXæ˜¯ Open Neural Network Exchange çš„ç¼©å†™ï¼Œæ˜¯ä¸€ç§ç”¨äºè¡¨ç¤ºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¼€æ”¾æ ¼å¼ã€‚å®ƒä½¿å¾—ä¸åŒçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚ TensorFlowã€PyTorchã€Caffe2 ç­‰ï¼‰å¯ä»¥ç›¸äº’è½¬æ¢å’Œå…±äº«æ¨¡å‹ã€‚

ONNX Runtime æ˜¯ç”±å¾®è½¯å¼€å‘çš„ä¸€æ¬¾æ¨ç†æ¡†æ¶ï¼Œç”¨äºåœ¨å¤šç§è¿è¡Œåç«¯ï¼ˆå¦‚ CPUã€GPUã€TensorRTã€DML ç­‰ï¼‰ä¸Šè¿è¡Œ ONNX æ ¼å¼çš„æ¨¡å‹ ã€‚ONNX Runtimeæ”¯æŒè·¨å¹³å°ã€é«˜æ€§èƒ½çš„æ·±åº¦å­¦ä¹ æ¨ç†ï¼Œå¯ä»¥åŠ è½½å’Œè¿è¡Œ ONNX æ ¼å¼çš„æ¨¡å‹ ã€‚å®ƒå¯ä»¥ä¸å„ç§æ·±åº¦å­¦ä¹ æ¡†æ¶æ— ç¼é›†æˆï¼Œæä¾›äº†ç®€å•æ˜“ç”¨çš„ APIï¼Œå¹¶æ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€å’Œå¹³å°

#### 2.å¯¼å‡ºonnxæ ¼å¼
å¯¼å‡ºå¯ä»¥ç›´æ¥ä½¿ç”¨YOLOv8å®˜æ–¹å°è£…å¥½çš„`export`æ–¹æ³•ï¼Œæ”¯æŒå¤šç§æ ¼å¼å¯¼å‡ºï¼Œå…¶ä¸­å°±åŒ…æ‹¬ONNX

å…·ä½“å‚æ•°é€‰é¡¹å¯å‚è€ƒ[å®˜æ–¹æ–‡æ¡£](https://docs.ultralytics.com/modes/export/#arguments)ï¼Œè¿è¡Œå¦‚ä¸‹ä»£ç ï¼Œå¯¼å‡ºä¸ºONNXæ ¼å¼ï¼š
```python
from ultralytics import YOLO

model = YOLO('./rps_best.pt') # åŠ è½½ä¹‹å‰è®­ç»ƒå¥½çš„æ¨¡å‹
model.export(format='onnx')
```
æ§åˆ¶å°è¾“å‡ºå¦‚ä¸‹ï¼š
```shell
Ultralytics YOLOv8.1.45 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)
Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs

[34m[1mPyTorch:[0m starting from 'rps_best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (6.0 MB)
[31m[1mrequirements:[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...
Collecting onnx>=1.12.0
  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 15.9/15.9 MB 41.0 MB/s eta 0:00:00
Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.25.2)
Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)
Installing collected packages: onnx
Successfully installed onnx-1.16.0

[31m[1mrequirements:[0m AutoUpdate success âœ… 18.0s, installed 1 package: ['onnx>=1.12.0']
[31m[1mrequirements:[0m âš ï¸ [1mRestart runtime or rerun command for updates to take effect[0m


[34m[1mONNX:[0m starting export with onnx 1.16.0 opset 17...
[34m[1mONNX:[0m export success âœ… 20.5s, saved as 'rps_best.onnx' (11.7 MB)

Export complete (25.5s)
Results saved to [1m/content[0m
Predict:         yolo predict task=detect model=rps_best.onnx imgsz=640  
Validate:        yolo val task=detect model=rps_best.onnx imgsz=640 data=./datasets/data.yaml  
Visualize:       https://netron.app

'rps_best.onnx'
```
å¯¼å‡ºçš„æ¨¡å‹å¤§æ¦‚æœ‰12Mï¼Œè¾“å‡ºä¿¡æ¯ä¸­æœ‰ä¸€ä¸ª`opset 17`æ¯”è¾ƒé‡è¦ï¼Œè¡¨ç¤ºå¯¹æ¨¡å‹ç®—å­çš„æ”¯æŒç‰ˆæœ¬ï¼Œè¾ƒæ–°çš„ç‰ˆæœ¬æ”¯æŒæ›´å¤šç®—å­ï¼Œè¾ƒè€çš„åˆ™å¯¹å¹³å°å…¼å®¹æ€§æ›´å¥½ï¼Œè¯¦æƒ…å¯å‚è€ƒ[å®˜æ–¹è¯´æ˜](https://onnxruntime.ai/docs/reference/compatibility.html)

### å››ã€æ­é…onnxruntimeçš„æ•°æ®é¢„å¤„ç†
#### 1.YOLOv8å’Œonnxruntimeåœ¨ä½¿ç”¨ä¸Šçš„åŒºåˆ«
å¯¹äºç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆæ¯”å¦‚YOLOv8ï¼‰çš„æ¨ç†è¿‡ç¨‹ï¼Œé€šå¸¸æ˜¯è¿™æ ·çš„:
- (1)è¯»å–å›¾ç‰‡ 
- (2)å¯¹å›¾ç‰‡æ•°æ®åšé¢„å¤„ç†ï¼Œä»¥ç¬¦åˆæ¨¡å‹inputå±‚çš„æ ¼å¼
- (3)æ¨¡å‹åŠ è½½å¤„ç†åçš„å›¾ç‰‡æ•°æ®
- (4)æ¨¡å‹è¾“å‡º
- (5)è§£ææ¨¡å‹è¾“å‡ºï¼Œå°†ç›¸å…³ä¿¡æ¯ç»˜åˆ¶åˆ°åŸå§‹å›¾ç‰‡ä¸Š

æ¯”å¦‚YOLOv8å®˜æ–¹å·²ç»å°†ä¸Šè¿°æ­¥éª¤éƒ½å°è£…åœ¨äº†`predict`æ–¹æ³•é‡Œï¼Œç›´æ¥è°ƒç”¨å°±è¡Œã€‚ä½†æ˜¯onnxruntimeä¸åŒï¼Œå› ä¸ºå®ƒéœ€è¦æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æ¶ã€å¤šä¸ªå¹³å°ã€å„ç§ä¸åŒçš„æ¨¡å‹ï¼Œå®ƒå®ç°çš„æ˜¯ä¸€ä¸ªé€šç”¨çš„APIï¼ŒåªåŒ…å«ä¸Šè¿°è¿‡ç¨‹çš„(3)å’Œ(4)ï¼Œå…¶ä»–éœ€è¦æˆ‘ä»¬è‡ªå·±æ¥å®ç°ã€‚

#### 2.pythonç‰ˆçš„æ•°æ®é¢„å¤„ç†
å…ˆä»‹ç»pythonçš„å®ç°ï¼Œå› ä¸ºpythonåœ¨å¯¹æ•°æ®å¼ é‡çš„å¤„ç†æ–¹é¢ï¼Œæœ‰å¾ˆå¤šé«˜æ•ˆçš„åº“ï¼Œèƒ½è®©æ•´ä¸ªæµç¨‹çœ‹èµ·æ¥æ›´æ¸…æ™°æ˜“æ‡‚ã€‚

å®‰è£…å¹¶å¯¼å…¥onnxruntime
```python
!pip install onnxruntime
import onnxruntime as ort
```

åŠ è½½onnxæ¨¡å‹å¹¶å®ä¾‹åŒ–
```python
ort_model = ort.InferenceSession('./rps_best.onnx')
```

æŸ¥çœ‹æ¨¡å‹inputå±‚shape
```python
for input in ort_model.get_inputs():
    print("input name: ", input.name)
    print("input shape: ", input.shape)
    print("input type: ", input.type)
```

æ‰“å°ç»“æœå¦‚ä¸‹: 
```python
Name: images
Type: tensor(float)
Shape: [1, 3, 640, 640]
```
è¾“å…¥ä¸ºå››ç»´æµ®ç‚¹æ•°æ®ï¼ŒåŒ…å«ä¸€å¼ 3é€šé“ï¼ˆRGBï¼‰çš„å›¾ç‰‡ï¼Œå°ºå¯¸640x640ï¼Œåƒä¸‹é¢è¿™æ ·ï¼š

![rps_rgb_input](../images/rps_rgb_input.png)

ä»¥å•å¼ å›¾ç‰‡ä¸ºä¾‹ï¼Œä½¿ç”¨PILè°ƒæ•´å›¾ç‰‡å°ºå¯¸
```python
!pip install pillow
from PIL import Image

img = Image.open("test.jpg")
img_width, img_height = img.size
img = img.resize((640,640))
```
åˆ é™¤alphaé€šé“
```python
img = img.convert("RGB")
```

å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸ºæµ®ç‚¹æ•°çŸ©é˜µ
```python
import numpy as np

input = np.array(img)
```

æŸ¥çœ‹å½“å‰æ•°æ®çš„shape
```python
input.shape
output:(640, 640, 3)
```

ç”±äºæˆ‘ä»¬éœ€è¦çš„æ˜¯(3, 640, 640)ï¼Œå¾—åšä¸€ä¸‹è½¬æ¢
```python
input = input.transpose(2,0,1)

input.shape
output:(3, 640, 640)
```

ç”±äºéœ€è¦çš„æ ¼å¼æ˜¯å››ç»´çš„ï¼Œè¿˜è¦åšä¸€ä¸‹å‡ç»´
```python
input = input.reshape(1,3,640,640) #æˆ–è€…ç”¨expand_dims

input.shape
output:(1, 3, 640, 640)
```

shapeå¯¹äº†ï¼Œè¿˜è¦å¯¹æ•°æ®åšå½’ä¸€åŒ–
```python
input = input/255.0

input[0,0,0,0]
output: 0.9137254901960784
```
è‡³æ­¤ï¼Œpythonç‰ˆçš„æ•°æ®é¢„å¤„ç†å®Œæˆ

#### 3.javascriptç‰ˆçš„æ•°æ®é¢„å¤„ç†
é¦–å…ˆï¼Œé€šè¿‡canvasçš„`getImageData`è·å–å›¾ç‰‡çš„åƒç´ æ•°ç»„
```javascript
function prepare_input(img) {
  const canvas = document.createElement("canvas");
  canvas.width = 640;
  canvas.height = 640;
  const context = canvas.getContext("2d");
  context.drawImage(img, 0, 0, 640, 640);

  const data = context.getImageData(0, 0, 640, 640).data;
}
```
æ­¤æ—¶æ‹¿åˆ°çš„dataæ˜¯ä¸€ä¸ªä¸€ç»´æ•°ç»„ï¼Œéœ€è¦æŒ‰ä¸‹å›¾åšè½¬æ¢ï¼š
![rps_js_rgb_array](../images/rps_js_rgb_array.png)

```python
  const red = [],
  green = [],
  blue = [];
  
  for (let index = 0; index < data.length; index += 4) {
    red.push(data[index] / 255);
    green.push(data[index + 1] / 255);
    blue.push(data[index + 2] / 255);
  }
  return [...red, ...green, ...blue];
```
javascriptç‰ˆçš„æ•°æ®é¢„å¤„ç†å°±æ˜¯è¿™äº›

### äº”ã€æ­é…onnxruntimeçš„æ•°æ®åå¤„ç†
#### 1.pythonç‰ˆçš„æ•°æ®åå¤„ç†
å…ˆæŸ¥çœ‹æ¨¡å‹è¾“å‡ºçš„shape
```python
outputs = ort_model.get_outputs()
output = outputs[0]
print("Name:",output.name)
print("Type:",output.type)
print("Shape:",output.shape)
```
æ‰“å°ç»“æœå¦‚ä¸‹ï¼šæ¨¡å‹è¿”å›ä¸€ä¸ªä¸‰ç»´æµ®ç‚¹æ•°ç»„ï¼Œä»£è¡¨ä¸€å¼ å›¾ç‰‡ä¸Šæœ‰8400ä¸ªæ£€æµ‹æ¡†ï¼ˆ8400æ˜¯YOLOv8å¯ä»¥æ£€æµ‹çš„æœ€å¤§è¾¹ç•Œæ¡†æ•°é‡ï¼Œå¹¶ä¸”æ— è®ºå®é™…æ£€æµ‹åˆ°å¤šå°‘ä¸ªå¯¹è±¡ï¼Œå®ƒéƒ½ä¼šä¸ºä»»ä½•å›¾åƒè¿”å› 8400 è¡Œï¼‰ï¼Œæ¯ä¸ªæ¡†æœ‰4ä¸ªåæ ‡ç‚¹ä¿¡æ¯+3ä¸ªç±»åˆ«ç½®ä¿¡åº¦
```shell
Name: output0
Type: tensor(float)
Shape: [1, 7, 8400]
```
å¯ä»¥ç”¨æ¨¡å‹è·‘ä¸€ä¸‹æ¨ç†ï¼Œçœ‹ä¸€ä¸‹å®é™…çš„è¾“å‡º
```python
input = input.astype(np.float32) # inputä»£è¡¨é¢„å¤„ç†åçš„æ•°æ®ï¼Œè¿™é‡Œå…ˆè½¬æˆå•ç²¾åº¦æµ®ç‚¹
outputs = ort_model.run(["output0"], {"images":input})
output = outputs[0]
output.shape # (1, 7, 8400)
```
å–å‡ºå…¶ä¸­çš„äºŒç»´æ•°æ®ï¼Œåšè½¬ç½®ï¼Œæ–¹ä¾¿åç»­å¤„ç†
```python
output = output[0]
output.shape # (7, 8400)
output = output.transpose() # è½¬ç½®
output.shape # (8400, 7)
```
è¿™é‡Œçš„(8400, 7)ä»£è¡¨æœ‰8400è¡Œ7åˆ—ï¼Œå¯ä»¥çœ‹ä¸‹ç¬¬ä¸€è¡Œçš„æ•°æ®
```python
row = output[0]
print(row) 
# [     14.623      22.475      29.157      45.249  1.4901e-07  3.2783e-07  5.9605e-08]
```
å‰4é¡¹ä»£è¡¨æ£€æµ‹æ¡†çš„xcenterã€ycenterã€widthã€heightï¼Œåé¢3é¡¹ä»£è¡¨'Paper', 'Rock', 'Scissors'çš„æ¦‚ç‡ï¼Œè¿™é‡Œéœ€è¦å°†åæ ‡ä¿¡æ¯è½¬æ¢ä¸ºx1y1(çŸ©å½¢æ¡†å·¦ä¸Šè§’),x2y2(çŸ©å½¢æ¡†å³ä¸‹è§’)å½¢å¼ï¼Œæ–¹ä¾¿ç”»å›¾ï¼Œè¿˜è¦è·å–æœ€å¤§æ¦‚ç‡å€¼å’Œå¯¹åº”çš„ç±»åˆ«
```python
yolo_classes = ['Paper', 'Rock', 'Scissors']

def parse_row(row):
    xc,yc,w,h = row[:4]
    x1 = (xc-w/2)/640*img_width
    y1 = (yc-h/2)/640*img_height
    x2 = (xc+w/2)/640*img_width
    y2 = (yc+h/2)/640*img_height
    prob = row[4:].max()
    class_id = row[4:].argmax()
    label = yolo_classes[class_id]
    return [x1,y1,x2,y2,label,prob]
```
å¯¹äºæ¨¡å‹è¿”å›çš„æ¦‚ç‡è¾ƒä½çš„æ£€æµ‹æ¡†æˆ‘ä»¬éœ€è¦è¿‡æ»¤æ‰ï¼Œè¿™é‡Œè®¾ç½®ä¸¢å¼ƒæ¦‚ç‡<0.5çš„æ¡†
```python
boxes = [row for row in [parse_row(row) for row in output] if row[5]>0.5]

len(boxes) # 20
```
è¿˜æœ‰20ä¸ªæ¡†ï¼Œå°†è¿™20ä¸ªæ¡†ç»˜åˆ¶åˆ°æµ‹è¯•å›¾ç‰‡ä¸Šï¼Œå¯ä»¥å‘ç°å®ƒä»¬å¾ˆå¤šéƒ½æ˜¯é‡å çš„
```python
from PIL import ImageDraw
img = Image.open("test.jpg")
draw = ImageDraw.Draw(img)

for box in boxes:
    x1,y1,x2,y2,class_id,prob = box
    draw.rectangle((x1,y1,x2,y2),None,"#00ff00")
```
![](../images/rps_test_output.png)
è¿™æ—¶å€™å°±éœ€è¦ä½¿ç”¨NMSç®—æ³•åšå¤„ç†

#### 2.IoUä¸NMSçš„å®ç°
IoUï¼šå¯ä»¥ä½¿ç”¨IoUï¼ˆIntersection over Unionï¼Œäº¤å¹¶æ¯”ï¼‰æ¥åˆ¤æ–­æ£€æµ‹æ¡†å®šä½çš„å¥½åã€‚æ‰€è°“äº¤å¹¶æ¯”ï¼Œæ˜¯æŒ‡é¢„æµ‹è¾¹æ¡†ä¸å®é™…è¾¹æ¡†çš„äº¤é›†å’Œå¹¶é›†çš„æ¯”ç‡ï¼Œå–å€¼èŒƒå›´ä¸º0ï½1ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½
![iou.png](../images/iou.png)
ä»£ç å®ç°ï¼š
```python
def intersection(box1,box2):
    box1_x1,box1_y1,box1_x2,box1_y2 = box1[:4]
    box2_x1,box2_y1,box2_x2,box2_y2 = box2[:4]
    x1 = max(box1_x1,box2_x1)
    y1 = max(box1_y1,box2_y1)
    x2 = min(box1_x2,box2_x2)
    y2 = min(box1_y2,box2_y2)
    return (x2-x1)*(y2-y1)
    
def union(box1,box2):
    box1_x1,box1_y1,box1_x2,box1_y2 = box1[:4]
    box2_x1,box2_y1,box2_x2,box2_y2 = box2[:4]
    box1_area = (box1_x2-box1_x1)*(box1_y2-box1_y1)
    box2_area = (box2_x2-box2_x1)*(box2_y2-box2_y1)
    return box1_area + box2_area - intersection(box1,box2)
    
def iou(box1,box2):
    return intersection(box1,box2)/union(box1,box2) 
```


NMSï¼šé¢„æµ‹ç»“æœä¸­ï¼Œå¯èƒ½å¤šä¸ªé¢„æµ‹ç»“æœé—´å­˜åœ¨é‡å éƒ¨åˆ†ï¼Œéœ€è¦ä¿ç•™äº¤å¹¶æ¯”ï¼ˆIoUï¼‰æœ€å¤§çš„ã€å»æ‰éæœ€å¤§çš„é¢„æµ‹ç»“æœï¼Œè¿™å°±æ˜¯éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNon-Maximum Suppressionï¼Œç®€å†™ä½œNMSï¼‰

NMSçš„ç®—æ³•æ­¥éª¤å¦‚ä¸‹ï¼š
- å°†æ‰€æœ‰æ¡†æ”¾å…¥é˜Ÿåˆ—ä¸­
- å…ˆæ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜çš„æ¡†ï¼ˆå‡è®¾ä¸ºAï¼‰
- å°†Aæ”¾å…¥ç»“æœæ•°ç»„ä¸­
- ä¾æ¬¡è®¡ç®—å…¶ä»–æ¡†ä¸Açš„IoUå€¼
- å¦‚æœæŸä¸ªæ¡†ï¼ˆå‡è®¾ä¸ºBï¼‰çš„IoUå¤§äºç»™å®šé˜ˆå€¼ï¼ˆæ¯”å¦‚0.7ï¼‰ï¼Œåˆ™è®¤ä¸ºBå’ŒAæ¡†å®šçš„æ˜¯åŒä¸€ä¸ªç‰©ä½“ï¼Œåˆ é™¤B
- å¾ªç¯ä¸Šè¿°æ­¥éª¤ï¼Œç›´åˆ°é˜Ÿåˆ—ä¸­æ²¡æœ‰æ¡†äº†

ä»£ç å®ç°ï¼š
```python
# NMS
boxes.sort(key=lambda x: x[5], reverse=True)

result = []

while len(boxes)>0:
    result.append(boxes[0])
    boxes = [box for box in boxes if iou(box,boxes[0])<0.7] #<0.7åˆ™ä¸æ˜¯åŒä¸€ç‰©ä½“ï¼Œè¦ä¿ç•™
```
ç»è¿‡NMSå¤„ç†åï¼Œresultä¸­åªå‰©2ä¸ªæ¡†äº†
```python
print(result)

[[316.81634521484375,
  242.34803009033203,
  517.7810668945312,
  431.6143112182617,
  'Scissors',
  0.9387282],
 [69.72752380371094,
  226.46387481689453,
  205.6693878173828,
  435.36669158935547,
  'Rock',
  0.9296297]]
```

#### 3.javascriptç‰ˆçš„æ•°æ®åå¤„ç†
è®¡ç®—IoUçš„å®ç°
```javascript
function iou(box1, box2) {
  return intersection(box1, box2) / union(box1, box2);
}

function union(box1, box2) {
  const [box1_x1, box1_y1, box1_x2, box1_y2] = box1;
  const [box2_x1, box2_y1, box2_x2, box2_y2] = box2;
  const box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1);
  const box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1);
  return box1_area + box2_area - intersection(box1, box2);
}

function intersection(box1, box2) {
  const [box1_x1, box1_y1, box1_x2, box1_y2] = box1;
  const [box2_x1, box2_y1, box2_x2, box2_y2] = box2;
  const x1 = Math.max(box1_x1, box2_x1);
  const y1 = Math.max(box1_y1, box2_y1);
  const x2 = Math.min(box1_x2, box2_x2);
  const y2 = Math.min(box1_y2, box2_y2);
  return (x2 - x1) * (y2 - y1);
}
```

è·å–x1ã€y1ã€x2ã€y2ã€æœ€å¤§ç½®ä¿¡åº¦å’Œå¯¹åº”çš„ç±»åˆ«ï¼Œè¿™é‡Œæ²¡æœ‰åšè¡Œåˆ—çš„è½¬ç½®ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨äº†ç»å¯¹ç´¢å¼•æ¥å®šä½
```javascript
for (let index = 0; index < 8400; index++) {
    const [class_id, prob] = [...Array(yolo_classes.length).keys()]
      .map((col) => [col, output[8400 * (col + 4) + index]])
      .reduce((accum, item) => (item[1] > accum[1] ? item : accum), [0, 0]);
    if (prob < 0.5) {
      continue;
    }
    const label = yolo_classes[class_id];
    const xc = output[index];
    const yc = output[8400 + index];
    const w = output[2 * 8400 + index];
    const h = output[3 * 8400 + index];
    const x1 = ((xc - w / 2) / 640) * img_width;
    const y1 = ((yc - h / 2) / 640) * img_height;
    const x2 = ((xc + w / 2) / 640) * img_width;
    const y2 = ((yc + h / 2) / 640) * img_height;
    boxes.push([x1, y1, x2, y2, label, prob]);
}
```
NMSç®—æ³•å®ç°ï¼š
```javascript
let boxes = [];
boxes = boxes.sort((box1, box2) => box2[5] - box1[5]);

const result = [];
while (boxes.length > 0) {
    result.push(boxes[0]);
    boxes = boxes.filter((box) => iou(boxes[0], box) < 0.7);
}
```

### å…­ã€æ¨¡å‹éƒ¨ç½²ä¸æ¨ç†
åœ¨æµè§ˆå™¨ä¸Šéƒ¨ç½²ï¼Œç”¨åˆ°çš„æ˜¯`onnxruntime-web`è¿™ä¸ªlibraryï¼Œå®ƒå¯ä»¥è°ƒç”¨ç«¯ä¾§çš„cpu(wasm)ã€webglæˆ–webGPUæ¥æ‰§è¡Œæ¨¡å‹æ¨ç†ã€‚æˆ‘è¿™é‡Œä½¿ç”¨çš„æ˜¯cpuæ¥æ‰§è¡Œï¼Œå› ä¸ºå…¼å®¹æ€§æ¯”è¾ƒå¥½ã€‚

onnxå®˜æ–¹æ¨èæŠŠæ¨¡å‹æ¨ç†è¿™éƒ¨åˆ†ä»£ç ï¼Œæ”¾åˆ°web workerä¸­æ‰§è¡Œï¼Œå› ä¸ºæ˜¯cpuå¯†é›†å‹æ“ä½œï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢é˜»å¡ä¸»çº¿ç¨‹ï¼Œå…·ä½“å‚è€ƒ[å®˜æ–¹æ–‡æ¡£](https://onnxruntime.ai/docs/tutorials/web/performance-diagnosis.html)
![rps_onnx_worker](../images/rps_onnx_worker.png)

worker.jsçš„ä»£ç å¦‚ä¸‹
```javascript
importScripts(
  "https://cdn.jsdelivr.net/npm/onnxruntime-web@1.17.1/dist/ort.min.js",
);

let model = null;
ort.InferenceSession.create("./rps_best.onnx", {
  executionProviders: ["wasm"],
  graphOptimizationLevel: "all",
}).then((res) => {
  model = res;
  console.log("model", model);
  postMessage({ type: "modelLoaded" });
});

async function run_model(input) {
  if (!model) {
    model = await model;
  }
  input = new ort.Tensor(Float32Array.from(input), [1, 3, 640, 640]);
  const outputs = await model.run({ images: input });
  return outputs["output0"].data;
}

onmessage = async (event) => {
  const { input, startTime } = event.data;
  const output = await run_model(input);
  postMessage({ type: "modelResult", result: output, startTime });
};

```
ç»˜åˆ¶æœ€ç»ˆæ£€æµ‹æ¡†çš„ä»£ç å¦‚ä¸‹ï¼š
```javascript
function draw_boxes(canvas, boxes) {
  const ctx = canvas.getContext("2d");
  ctx.strokeStyle = "#00FF00";
  ctx.lineWidth = 3;
  ctx.font = "18px serif";
  boxes.forEach(([x1, y1, x2, y2, label]) => {
    ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
    ctx.fillStyle = "#00ff00";
    const width = ctx.measureText(label).width;
    ctx.fillRect(x1, y1, width + 10, 25);
    ctx.fillStyle = "#000000";
    ctx.fillText(label, x1, y1 + 18);
  });

  // ç»˜åˆ¶ Infer count å’Œ Average infer time
  ctx.font = "16px Arial";
  ctx.fillStyle = "black";
  ctx.fillText(`Infer count: ${inferCount}`, 10, 20);
  ctx.fillText(
    `Average infer time: ${
      inferCount ? parseInt(totalInferTime / inferCount) : 0
    } ms`,
    10,
    40,
  );
}
```

åˆšå¼€å§‹è¿è¡Œï¼Œé™¤äº†ä¼šåŠ è½½æ¨¡å‹æ–‡ä»¶ï¼ˆ12.2Mï¼‰ï¼Œè¿˜ä¼šåŠ è½½ä¸€ä¸ªwasm libraryï¼ˆ2.6Mï¼‰ä½œä¸ºbackendæ¥è°ƒç”¨cpuèµ„æº
![img.png](../images/rps_run_init.png)

åœ¨æˆ‘çš„ Mac M1 Chromeæµè§ˆå™¨ä¸Šï¼Œå¹³å‡æ¨ç†ä¸€æ¬¡å·®ä¸å¤šè¦600msï¼ˆå¦‚ä¸‹å›¾ï¼‰
![rps_infer_600](../images/rps_infer_600.png)

åç»­ä¸»è¦ä»ä¸¤ä¸ªæ–¹å‘ç€æ‰‹ä¼˜åŒ–ï¼š
- å‡å°æ¨¡å‹æ–‡ä»¶å°ºå¯¸ï¼Œæå‡åŠ è½½é€Ÿåº¦
- æŒ–æ˜ç«¯ä¾§æ€§èƒ½ï¼Œä»è€Œé™ä½æ¨ç†è€—æ—¶

### ä¸ƒã€ä¼˜åŒ–
#### 1.æ¨¡å‹é‡åŒ–
æ¨¡å‹é‡åŒ–æ˜¯æŒ‡å°†æ¨¡å‹ä¸­çš„æµ®ç‚¹æƒé‡å’Œæ¿€æ´»å€¼è½¬æ¢ä¸ºä½ç²¾åº¦æ•´æ•°ç±»å‹ï¼Œä¾‹å¦‚ int8 æˆ– int16 çš„è¿‡ç¨‹ï¼Œè¿™å¯ä»¥æ˜¾è‘—å‡å°æ¨¡å‹çš„å¤§å°å’Œå†…å­˜å ç”¨

æˆ‘è¿™é‡Œä½¿ç”¨äº†åŠ¨æ€uint8é‡åŒ–ï¼Œåœ¨é‡åŒ–å‰è¿˜éœ€è¦åšä¸€æ¬¡preprocessï¼Œå…¶ä¸­åŒ…å«äº†å¯¹modelçš„optimizeï¼Œå…·ä½“å¯å‚è€ƒ[å®˜æ–¹æ–‡æ¡£](https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html)
```python
!pip install onnxruntime

# https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md
!python -m onnxruntime.quantization.preprocess --input rps_best.onnx --output rps_best_infer.onnx

from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType
model_fp32 = './rps_best_infer.onnx'
model_quant = './rps_best_uint8.onnx'
quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)
```
é‡åŒ–åçš„æ¨¡å‹ï¼Œå¤§å°ä»12.2Mï¼Œå‡å°‘åˆ°3.3Mï¼Œä½“ç§¯å‡å°äº†å››åˆ†ä¹‹ä¸€
![rps_uint8](../images/rps_uint8.png)

#### 2.ä½¿ç”¨SIMD+å¤šçº¿ç¨‹åŠ é€Ÿwasm backend
SIMD æ˜¯ Single Instruction, Multiple Data çš„ç¼©å†™ï¼ŒæŒ‡çš„æ˜¯å•æŒ‡ä»¤å¤šæ•°æ®ã€‚SIMD æŒ‡ä»¤å¯ä»¥åŒæ—¶å¯¹å¤šä¸ªæ•°æ®è¿›è¡Œæ“ä½œï¼Œä»è€Œæé«˜æ•°æ®å¤„ç†é€Ÿåº¦

å¤šçº¿ç¨‹å¯ä»¥æœ‰æ•ˆåˆ©ç”¨å¤šæ ¸CPUèµ„æºï¼Œä»è€Œæé«˜æ€§èƒ½
![rps_simd_thread](../images/rps_simd_thread.png)

onnxruntime-webçš„SIMDæ˜¯é»˜è®¤å¼€å¯çš„ï¼Œè€Œå¤šçº¿ç¨‹éœ€è¦æœåŠ¡ç«¯è¿”å›COOP/COEPå“åº”å¤´ï¼Œä»¥åœ¨æµè§ˆå™¨ç«¯å¯ç”¨è·¨åŸŸéš”ç¦»ï¼ˆå¦‚ä¸‹å›¾ï¼‰ï¼Œè¯¦æƒ…å‚è€ƒ[è¿™é‡Œ](https://web.dev/articles/cross-origin-isolation-guide?hl=zh-cn)
![rps_multi_thread](../images/rps_multi_thread.png)

ç”±äºæˆ‘ä½¿ç”¨çš„verceléƒ¨ç½²ï¼Œç›´æ¥åœ¨`vercel.json`ä¸­æ·»åŠ é…ç½®å³å¯è®©vercelè¿”å›ç›¸å…³httpå¤´
```json
{
  "headers": [
    {
      "source": "/(.*)",
      "headers": [
        {
          "key": "Cross-Origin-Embedder-Policy",
          "value": "require-corp"
        },
        {
          "key": "Cross-Origin-Opener-Policy",
          "value": "same-origin"
        }
      ]
    }
  ]
}

```
å¯ç”¨wasmå¤šçº¿ç¨‹åï¼Œåœ¨PCç«¯Chromeä¸Šçš„å¹³å‡æ¨ç†æ—¶é—´ï¼Œä»600mså·¦å³å‡å°‘åˆ°269ms
![img.png](../images/rps_infer_300.png)

### å…«ã€æœ‰å¾…æ”¹è¿›çš„åœ°æ–¹
1.æœ€æ–°ç‰ˆonnxæ”¯æŒint4é‡åŒ–ï¼Œå¯ä»¥è¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹ä½“ç§¯ï¼Œå‡å°‘é€šè¿‡ç½‘ç»œä¼ è¾“çš„æ•°æ®é‡

2.å°è¯•å°†æ¨¡å‹èµ„æºéƒ¨ç½²åˆ°å›½å†…èŠ‚ç‚¹ï¼Œæå‡ä¼ è¾“é€Ÿåº¦å’Œç¨³å®šæ€§

3.åœ¨æ‰‹æœºæµè§ˆå™¨ä¸Šæµ‹è¯•ï¼Œå¹³å‡æ¨ç†æ—¶é—´éœ€è¦1600ms~2000msï¼Œä¸ç¡®å®šæ˜¯æ‰‹æœºè®¡ç®—èµ„æºå­±å¼±ï¼Œè¿˜æ˜¯æŸäº›åŠ é€ŸåŠŸèƒ½æœªå¼€å¯ï¼Œæœ‰å¾…éªŒè¯

4.åœ¨å°è¯•ä½¿ç”¨WebGLå’ŒWebGPU provideræ—¶ï¼Œé‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¿˜æœªè§£å†³ï¼Œå¦‚æœèƒ½åˆ©ç”¨ç«¯ä¾§è®¾å¤‡çš„GPUèµ„æºï¼Œåˆ™å¯ä»¥æ›´å¥½å¾—åŠ é€Ÿæ¨¡å‹æ¨ç†

5.å¯ä»¥å°è¯•onnxä»¥å¤–çš„è§£å†³æ–¹æ¡ˆï¼Œä¹Ÿè®¸ä¼šæœ‰æ›´å¥½çš„æ€§èƒ½


å‚è€ƒï¼š

[ä½¿ç”¨ SIMD å’Œå¤šçº¿ç¨‹å¢å¼º TensorFlow.js WebAssembly åç«¯](https://www.infoq.cn/article/hi2vrxfevlelcvvov0g7)

[å…³äºå¯ç”¨è·¨åŸŸéš”ç¦»çš„æŒ‡å—](https://web.dev/articles/cross-origin-isolation-guide?hl=zh-cn)

[AIæ¨¡å‹éƒ¨ç½² | onnxruntimeéƒ¨ç½²RT-DETRç›®æ ‡æ£€æµ‹æ¨¡å‹](https://mp.weixin.qq.com/s/i_vAtCfM5eE6N6R5Sqo6zA)

[How to create YOLOv8-based object detection web service using Python, Julia, Node.js, JavaScript, Go and Rust](https://dev.to/andreygermanov/how-to-create-yolov8-based-object-detection-web-service-using-python-julia-nodejs-javascript-go-and-rust-4o8e#explore)

[ONNX Webå®˜æ–¹æ–‡æ¡£](https://onnxruntime.ai/docs/tutorials/web/)

[How to detect objects in videos in a web browser using YOLOv8 neural network and JavaScript](https://dev.to/andreygermanov/how-to-detect-objects-in-videos-in-a-web-browser-using-yolov8-neural-network-and-javascript-lfb)

[YOLOv8åˆä½“éªŒï¼šæ£€æµ‹ã€è·Ÿè¸ªã€æ¨¡å‹éƒ¨ç½²](https://juejin.cn/post/7210273155885645885)
