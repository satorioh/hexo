---
title: ML/DL复习
date: 2024-05-21 09:14:43
categories: ML
tags:
- ml
- dl
permalink: ml-review
---
#### 1.数据从哪里来？如何构建数据集？
```
1.现场自行采集（成本比较高）
2.甲方提供
3.网络下载现成的
4.企业真实的数据（商业价值最高）
5.购买（合法购买和使用，千万不要侵犯别人的隐私）
6.爬虫（合法使用，不要侵犯别人的隐私）

数据分门别类,进行标注
```
<!--more-->

#### 2.数据量多大？
```
深度学习越多越好
最起码每个类别数百级单位
```

#### 3.数据量不够如何处理？
```
数据增强
CV: 旋转、缩放、裁剪、调整色调、亮度、对比度、添加噪声。。。
NLP: 近义词替换、文本摘要。。。。
```

#### 4.采用的模型是什么？为什么使用YOLOv8？
```
效果
  依据：根据实际需求，以及项目的难易程度，选择现有的、经典的、成熟的模型，更换成自己的数据集，进行训练，并调参
  
  如果不确定模型，选择多个模型，进行对比，选择效果最好的
  
  在有些情况下，需要多个模型配合使用，发挥各自的特长

YOLOv8优势
    1.保持高精度的同时，具有更快的推理速度，适合实时检测
    2.多模型尺寸、多任务能力
    3.友好的文档、API、社区支持
```

#### 5.什么情况下使用OpenCV，什么情况下使用深度学习？
```
Opencv：不需要程序理解图像的场景和内容，图像相对单一，干扰因素较少，需求比较简单，数据量比较少
深度学习：需要程序理解图像的内容和场景，场景复杂，干扰因素多，样本变化大，需求复杂，数据量足够大
```

#### 6.准确率是多少？
```
工业中至少要95%以上，越高越好，不要过拟合
```

#### 7.写项目经验注意的问题
```
项目背景(需求)：用户是谁？用在什么地方？解决什么问题？
数据集：来源？数量？数据增强？标注？预处理手段？
模型：模型选择？训练过程？调参优化过程？
遇到了什么问题？怎么解决的？
过拟合，欠拟合问题怎么解决的？
效果？
部署？
```

#### 8.什么是有监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）？请举例说明每种类型的应用场景
```
有监督：训练数据集包含了标签，在训练过程中，模型学习输入与标签之间的映射关系
分类：图像分类、垃圾邮件分类
回归：房价预测

无监督：不依赖于标注数据，模型通过输入数据自行发现数据的结构或模式
聚类：客户分组
降维：从高维度数据中提取主要特征
```

#### 9.贝叶斯公式及推导过程
```
公式：P(A|B) = P(B|A)⋅P(A) / P(B)
解释：由先验概率和条件概率，推算出后验概率

推导：
由联合概率可知：P(A∩B)=P(A∣B)⋅P(B)
由联合概率对称性可知：P(A∩B)=P(B∣A)⋅P(A)
等式相等：P(A∣B)⋅P(B) = P(B∣A)⋅P(A)
两边除以P(B)得：P(A∣B) = P(B∣A)⋅P(A) / P(B)
```

#### 10.什么是似然？
```
概念：在已知某些数据的情况下，模型参数取特定值的概率
与概率的区别：概率描述的是在已知参数的情况下，观测到某数据的概率，而似然则是相反的情况，即在已知数据的情况下，参数的可能值
```

#### 11.什么是欠拟合、过拟合？如何避免过拟合？如何避免欠拟合？
```
欠拟合：指模型无法从训练数据中学习到足够的模式，导致其在训练集和测试集上都表现不佳
原因：模型表达能力不够、训练数据太少、训练时间不够
解决：
    1.增加模型复杂度
    2.增加特征数量
    3.增加训练数据
    4.训练更多轮数

过拟合：指模型在训练集上表现很好，但在测试集上表现较差，即模型过度适应了训练数据，忽略了数据的总体趋势，导致泛化能力差
原因：模型太复杂、数据集太小、训练时间过长
解决：
    1.数据增强
    2.正则化
    3.提前终止
    4.集成学习
    5.dropout
```

#### 12.神经网络加速训练方法有哪些？
```
硬件：多GPU、分布式训练
数据：归一化、数据增强
模型：更好的优化器、BN、量化、剪枝、使用预训练模型
训练：提前终止、混合精度训练、自动化超参数调整
```

#### 13.目标检测常用算法有哪些，简述对算法的理解
```
两阶段检测
   	先产生候选区，在候选区上分类+定位
   	速度相对比较慢，精度高
   	RCNN系列  
   	
一阶段检测
   	预定义候选区，直接在特征图上分类+定位
   	速度比较快，精度较低
   	YOLO系列、SSD、RetinaNet
```

#### 14.什么是感受野？

#### 15.L1、L2、smooth L1正则化的区别

#### 16.YOLOv8中的objectness loss是什么？

#### 17.什么是特征归一化？为什么要归一化？
```
归一化一般是将数据映射到指定的范围（[0, 1] 或 [-1, 1]），从而消除不同特征量纲的影响。
进行归一化处理，使得不同指标之间处于同一数量级，具有可比性。另外还能加速模型收敛，提升性能
```

#### 18.归一化常用方法？
```
Min-Max Normalization
公式：X = (X-Xmin) / (Xmax - Xmin)
--------------------------------------

import numpy as np
import sklearn.preprocessing as sp

raw_sample = np.array([[3.0, -100.0, 2000.0],
                       [0.0, 400.0, 3000.0],
                       [1.0, -400.0, 2000.0]])

mms_sample = raw_sample.copy()

# 1.减去最小值
# 2.减完之后的结果/极差
for col in mms_sample.T:
    col_min = col.min()
    col_max = col.max()
    col -= col_min
    col /= (col_max - col_min)
  
    
# 基于skLearn提供的API实现
scaler = sp.MinMaxScaler()
res = scaler.fit_transform(raw_sample)
```

#### 19.归一化处理适用模型
```
应用归一化的模型：在实际应用中，通过梯度下降法求解的模型通常是需要归一化的，包括线性回归、逻辑回归、支持向量机、神经网络等模型。
不使用归一化的模型：如决策树分类
```

#### 20.什么是标准化？常用方法？
```
标准化是将特征值调整为均值为0，标准差为1的标准正态分布

Z-Score Normalization
公式：X = (X - Xmean) / Xstd
-----------------------------------

import numpy as np
import sklearn.preprocessing as sp

raw_sample = np.array([[3.0, -100.0, 2000.0],
                       [0.0, 400.0, 3000.0],
                       [1.0, -400.0, 2000.0]])

std_sample = raw_sample.copy()

# 1.减去当前列的平均值
# 2.离差/原始数据的标准差
for col in std_sample.T:
    col_mean = col.mean()  # 平均值
    col_std = col.std()  # 标准差
    col -= col_mean
    col /= col_std

    
# 基于skLearn提供的API实现
scaler = sp.StandardScaler()
res = scaler.fit_transform(raw_sample)

```

#### 21.标准化和归一化的联系和区别
```
联系:
    我们都知道归一化是指normalization，标准化是指standardization，但根据wiki上对feature scaling方法的定义，standardization其实就是z-score normalization，也就是说标准化其实是归一化的一种，而一般情况下，我们会把z-score归一化称为标准化，把min-max归一化简称为归一化
    目的：都是通过缩放和平移来实现数据映射，消除不同特征量纲的影响

区别：
    归一化通常将数据映射到[0, 1]或[-1, 1]区间，而标准化则将数据映射到均值为0，标准差为1的正态分布
    归一化只受原样本数据中的极值影响，而标准化则受所有样本值的影响
    归一化对异常值敏感，而标准化则对异常值鲁棒
```

#### 22.均值、离差、离差方、方差、标准差之间的关系
```
import numpy as np

S = np.array([1, 2, 3, 4, 5, 6])

# 均值
mean = np.mean(S)
print(mean)  # 3.5

# 离差 = 观测值 - 均值
deviation = S - mean
print(deviation)  # [-2.5 -1.5 -0.5  0.5  1.5  2.5]

# 离差方 = 离差 ** 2
deviation_square = deviation ** 2
print(deviation_square)  # [6.25 2.25 0.25 0.25 2.25 6.25]

# 方差 = 离差方的均值
variance = np.mean(deviation_square)
print(variance)  # 2.9166666666666665

# 标准差 = 方差的平方根
std = np.sqrt(variance)
print(std)  # 1.707825127659933

```

#### 23.回归问题的模型评估指标
```
1.均方误差(Mean Squared Error, MSE)
  公式：MSE = Σ(y_i - y'_i)^2 / n
  取值：越小越好
  特点：L2范数，对离群值敏感，因为平方放大了误差

2.均方根误差（Root Mean Squared Error, RMSE）
  公式：RMSE = √MSE
  取值：越小越好
  特点：RMSE是MSE的平方根，其单位与原始数据相同，便于描述真实值。也对离群值敏感
  
3.平均绝对误差（Mean Absolute Error, MAE）
  公式：MAE = Σ|y_i - y'_i| / n
  取值：越小越好
  特点：L1范数，对离群值不敏感
  
4.决定系数/拟合优度（R² 或 Coefficient of Determination）
  解释：表示模型中自变量能解释因变量变异的百分比
  公式：R2 = 1 - MSE / Variance
  取值：0～1之间，越大越好
  特点：仅表示拟合程度，不代表模型预测准确度
```

#### 24.分类问题中的TP、FP、TN、FN是什么
```
TP：True Positive，正确得预测为正样本，实际就是正样本，即正样本被正确识别的数量
FP：False Positive，错误得预测为正样本，实际为负样本，即误报的数量
TN：True Negative，正确得预测为负样本，实际就是负样本，即负样本被正确识别的数量
FN：False Negative，错误得预测为负样本，实际为正样本，即漏报的数量

TP+FN：真实正样本的数量
FP+TN：真实负样本的数量
TP+FP：预测为正样本的数量
TN+FN: 预测为负样本的数量
TP+TN: 预测正确的数量
TP+TN+FP+FN: 样本总数量
```

#### 25.如何查看混淆矩阵
|           | Real A | Real B |
|-----------|--------|--------|
| Predict A | 10(TP) | 20(FP) |
| Predict B | 30(FN) | 5(TN)  |

```
该类的预测总数：某一行的和
该类的真实总数：某一列的和
预测对的数量：主对角线上的值

以A为例：
    TP: 预测为A，实际也为A = 10
    FP: 预测为A，实际不是A = 20
    TN: 预测为B，实际也为B = 5
    FN: 预测为B，实际为A = 30 
    Accuracy(和某个类别无关)：预测正确的数量 / 样本总数量 = 10 + 5 / 10 + 20 + 30 + 5
    Precision(A)：正确预测为A的数量 / 预测为A的数量（行） = 10 / 10 + 20
    Recall(A): 正确预测为A的数量 / 真实为A的数量（列） = 10 / 10 + 30
```

#### 26.分类问题的模型评估指标
```
注意：每个类别都有自己的查准率、召回率、f1得分

"""
假设有100张图片，50张狗（正样本），50张猫（负样本），模型预测结果为60张狗（其中有40张是正确的，还有20张是猫）、40张猫（10张狗 + 30张猫）
"""

1.准确率（Accuracy）
  公式：(TP+TN) / (TP+TN+FP+FN)
  解释：预测正确的数量 / 样本总数量 = (40 + 30) / 100 = 0.7
  特点：如果样本不平衡，则准确率就没有参考价值

2.查准率（Precision）
  公式：TP / (TP+FP) = 40 / 60 = 0.67
  解释：正确预测为正样本的数量 / 预测为正样本的数量。Precision越高，表示FP越小，即误报越少
  
3.召回率/查全率（Recall）
  公式：TP / (TP+FN) = 40 / 50 = 0.8
  解释：正确预测为正样本的数量 / 真实正样本的数量。Recall越高，表示FN越小，即漏报越少
  
4.F1分数（F1 Score）
  公式：F1 = 2 * Precision * Recall / (Precision + Recall)
  解释：F1分数是查准率和召回率的调和平均数，在两者之间取得平衡。适用于需要在查准率和召回率之间权衡的场景。
 
5.混淆矩阵（Confusion Matrix）
 
6.ROC和AUC
  ROC 曲线以FPR为横坐标，以TPR为纵坐标，连接不同阈值下的点绘制而成。
    真正率（TPR）= 灵敏度 = Recall = TP/(TP+FN)
    假正率（FPR） = 1- 特异度 = FP/(FP+TN)，代表有多少负样本被错误得预测成了正样本
  ROC 曲线越靠近左上角，说明模型性能越好
  
  AUC是 ROC 曲线下的面积，其值介于 0 和 1 之间，值越大，说明模型性能越好
  
  特点：可以避免样本不平衡的问题，因为TPR只关注正样本，FPR只关注负样本
```


